#This script runs the re-trained Inception model to classify a single or a batch of images

import subprocess
from PIL import Image
import matplotlib.pyplot as plt
import pathlib
from datetime import datetime
import time
import tensorflow as tf, sys
import numpy as np
import random

def plot_images(image, Caption1):

    #plt.close()
    
    plt.rcParams['text.usetex'] = False
    plt.rcParams['font.size'] = 10
    plt.rcParams['font.family'] = 'Arial'
    
    fig, ax = plt.subplots(1, 1)
    ax.imshow(image)
    xlabel = Caption1
    ax.set_xlabel(xlabel)
    ax.set_xticks([])
    ax.set_yticks([])
    plt.show()
    
def classify_image(image_path, model_path, labels_path):
    # Read in the image_data
    time_start = time.monotonic()
    config = tf.ConfigProto()
    config.gpu_options.allow_growth=True
    sess = tf.Session(config=config)

    image_data = tf.gfile.FastGFile(image_path, 'rb').read()

    # Loads label file, strips off carriage return
    label_lines = [line.rstrip() for line 
                       in tf.gfile.GFile(labels_path)]

    # Unpersists graph from file
    with tf.gfile.FastGFile(model_path, 'rb') as f:
        graph_def = tf.GraphDef()
        graph_def.ParseFromString(f.read())
        _ = tf.import_graph_def(graph_def, name='')

    with tf.Session() as sess:
        # Feed the image_data as input to the graph and get first prediction
        softmax_tensor = sess.graph.get_tensor_by_name('final_result:0')
        
        predictions = sess.run(softmax_tensor, \
                 {'DecodeJpeg/contents:0': image_data})
    
        # Sort to show labels of first prediction in order of confidence
        top_k = predictions[0].argsort()[-len(predictions[0]):][::-1]
    
        print(top_k, label_lines)
        output_label = ""
        
        for node_id in top_k:
            human_string = label_lines[node_id]
            score = predictions[0][node_id]
            output_label = output_label + human_string + "({0:.4f})".format(score) + " "
            #print('%s (score = %.5f)' % (human_string, score))
        #print(output_label)
        output_label = output_label + " Runtime: " + "{0:.2f}".format(time.monotonic()-time_start) + "s"
    
    image = Image.open(image_path)
    plot_images(image,output_label)
    sess.close()
	
# change this as you see fit; model_dir is the folder containing the retrained_graph.pb and retrained_labels.txt files generated by retrain.py; image_dir contains subfolders that contain the images to be assessed

model_dir = "C:/Users/Adonis Tio/Jupyter/face_shape_celebs3_testing"
imagedir = "C:/Users/Adonis Tio/Jupyter/Google Images/celebs3_sample"

model_path = model_dir + "/retrained_graph.pb"
labels_path = model_dir + "/retrained_labels.txt"
batch_run = 1

if (batch_run == 1):
	# Read in the image_data
	print("Initializing...")
	time_start = time.monotonic()
	config = tf.ConfigProto()
	config.gpu_options.allow_growth=True
	sess = tf.Session(config=config)

	# Loads label file, strips off carriage return
	label_lines = [line.rstrip() for line 
						in tf.gfile.GFile(labels_path)]

	# Unpersists graph from file
	with tf.gfile.FastGFile(model_path, 'rb') as f:
		graph_def = tf.GraphDef()
		graph_def.ParseFromString(f.read())
		_ = tf.import_graph_def(graph_def, name='')

	with tf.Session() as sess:
	
		# Feed the image_data as input to the graph and get first prediction
		softmax_tensor = sess.graph.get_tensor_by_name('final_result:0')
		sub_dir = [q for q in pathlib.Path(imagedir).iterdir() if q.is_dir()]
	
		result_summary = []
		labels = ['heart', 'oblong', 'oval', 'round', 'square']
		for j in range(len(sub_dir)):
			print("j = ",j, " ", sub_dir[j])
			images_dir = [p for p in pathlib.Path(sub_dir[j]).iterdir() if p.is_file()]
			for i in range(len(images_dir)):
				
				image_path = str(images_dir[i])
				image_data = tf.gfile.FastGFile(image_path, 'rb').read()
				predictions = sess.run(softmax_tensor, \
						{'DecodeJpeg/contents:0': image_data})
	
				# Sort to show labels of first prediction in order of confidence
				top_k = predictions[0].argsort()[-len(predictions[0]):][::-1]
	
				txt = str(images_dir[i]) + " " + label_lines[top_k[0]] + " " + str(top_k[0])+ " " + str(top_k[1])+ " " + str(top_k[2])+ " " + str(top_k[3])+ " " + str(top_k[4]) + "\n"
				print(image_path, " ", txt)
			
				output_label = ""
			
				for node_id in top_k:
					human_string = label_lines[node_id]
					score = predictions[0][node_id]
					output_label = output_label + human_string + "({0:.4f})".format(score) + " "
				output_label = output_label + " Runtime: " + "{0:.2f}".format(time.monotonic()-time_start) + "s"
	
				image = Image.open(image_path)
				plot_images(image,output_label)
		sess.close()


if (batch_run ==0):
	images_dir = [p for p in pathlib.Path(imagedir).iterdir() if p.is_file()]
	#print(dir(images_dir)) #print(images_dir.__sizeof__()) #print(type(images_dir)) #print(len(images_dir))

	for i in range(len(images_dir)):
		#print(images_dir[i], type(images_dir[i])) #print(str(images[i])) #Image.open(images_dir[i]).show()
		print("Processing ", images_dir[i], "...", end=' ', sep='') 
		classify_image(str(images_dir[i]), model_path, labels_path)
		plt.show()